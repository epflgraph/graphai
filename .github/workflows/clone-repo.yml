name: "Clone repo"

on:
  workflow_dispatch:

  workflow_call:

jobs:
  clone-repo:
    runs-on: self-hosted

    steps:
      - name: Debug
        env:
          GITHUB_CONTEXT: ${{ toJson(github) }}
        run: echo "$GITHUB_CONTEXT"

      - name: Checkout repository code
        uses: actions/checkout@v4
        with:
          path: main

      - name: Create config file
        run: |
          cd main

          echo "[celery]" >> config.ini
          echo "broker_url: ${{ vars.celery_broker_url }}" >> config.ini
          echo "result_backend: ${{ vars.celery_result_backend }}" >> config.ini
          echo "" >> config.ini

          echo "[database]" >> config.ini
          echo "host: ${{ vars.db_host }}" >> config.ini
          echo "port: ${{ vars.db_port }}" >> config.ini
          echo "user: ${{ vars.db_user }}" >> config.ini
          echo "password: ${{ secrets.db_password }}" >> config.ini
          echo "" >> config.ini

          echo "[auth]" >> config.ini
          echo "schema: ${{ vars.auth_schema }}" >> config.ini
          echo "secret_key: ${{ secrets.auth_key }}" >> config.ini
          echo "" >> config.ini

          echo "[elasticsearch]" >> config.ini
          echo "host: ${{ vars.es_host }}" >> config.ini
          echo "port: ${{ vars.es_port }}" >> config.ini
          echo "username: ${{ vars.es_username }}" >> config.ini
          echo "password: ${{ secrets.es_password }}" >> config.ini
          echo "cafile: ${{ vars.es_cafile }}" >> config.ini
          echo "concept_detection_index: ${{ vars.es_cd_index }}" >> config.ini
          echo "" >> config.ini

          echo "[cache]" >> config.ini
          echo "root: ${{ vars.cache_root }}" >> config.ini
          echo "schema: ${{ vars.cache_schema }}" >> config.ini
          echo "" >> config.ini

          echo "[whisper]" >> config.ini
          echo "model_type: ${{ vars.whisper_model_type }}" >> config.ini
          echo "model_path: ${{ vars.whisper_model_path }}" >> config.ini
          echo "" >> config.ini
          
          echo "[huggingface]" >> config.ini
          echo "model_path: ${{ vars.huggingface_model_path }}" >> config.ini
          echo "" >> config.ini
          
          echo "[fasttext]" >> config.ini
          echo "path: ${{ vars.fasttext_path }}" >> config.ini
          echo "dim: ${{ vars.fasttext_dim }}" >> config.ini
          echo "" >> config.ini

          echo "[google]" >> config.ini
          echo "api_key: ${{ secrets.google_api_key }}" >> config.ini
          echo "" >> config.ini

          echo "[openai]" >> config.ini
          echo "api_key: ${{ secrets.openai_api_key }}" >> config.ini
          echo "" >> config.ini

          echo "[preload]" >> config.ini
          echo "video: ${{ vars.preload_video }}" >> config.ini
          echo "text: ${{ vars.preload_text }}" >> config.ini
          echo "ontology: ${{ vars.preload_ontology }}" >> config.ini
          echo "embedding: ${{ vars.preload_embedding }}" >> config.ini
          echo "" >> config.ini
          
          echo "[ratelimiting]" >> config.ini
          echo "limit: ${{ vars.ratelimit_schema }}" >> config.ini
          echo "" >> config.ini
          

      - name: Install python package in editable mode
        run: |
          cd main
          source /data/venvs/test_venv/bin/activate
          pip install -e .

      - name: Install dependencies
        run: |
          cd main
          source /data/venvs/test_venv/bin/activate
          fasttext-reduce --root_dir ${{ vars.fasttext_path }} --lang en --dim ${{ vars.fasttext_dim }}
          fasttext-reduce --root_dir ${{ vars.fasttext_path }} --lang fr --dim ${{ vars.fasttext_dim }}
          python -c "import whisper; whisper.load_model('${{ vars.whisper_model_type }}', download_root='${{ vars.whisper_model_path }}');"
          python -c "from transformers import AutoModelForSeq2SeqLM; AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-tc-big-en-fr', cache_dir='${{ vars.huggingface_model_path }}')"
          python -c "from transformers import AutoModelForSeq2SeqLM; AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-tc-big-fr-en', cache_dir='${{ vars.huggingface_model_path }}')"
          python -c "from transformers import AutoModelForSeq2SeqLM; AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-de-en', cache_dir='${{ vars.huggingface_model_path }}')"
          python -c "from transformers import AutoModelForSeq2SeqLM; AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-it-en', cache_dir='${{ vars.huggingface_model_path }}')"
          python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2', cache_folder='${{ vars.huggingface_model_path }}')"
          python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('OrdalieTech/Solon-embeddings-large-0.1', cache_folder='${{ vars.huggingface_model_path }}')"
          opentelemetry-bootstrap --action=install

