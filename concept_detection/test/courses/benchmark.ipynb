{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e202f3d9-df12-488e-bc6a-2768facbd71c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Performance benchmark\n",
    "\n",
    "The aim of this notebook is to compare different elasticsearch settings in terms of performance and quality of results (closeness to ground truth).\n",
    "\n",
    "## Variables to fine-tune\n",
    "We establish the following values for different elasticsearch settings:\n",
    "\n",
    "1. Number of shards: 1, 3, 6, 12\n",
    "2. Max num segments: 1 (optimal for read-only indices)\n",
    "3. Query: We take as base query the mediawiki query (most complete, slow), and perform the following modifications to it:\n",
    "    * [`base`] No modification\n",
    "    * [`no-rescoring`] Skip rescoring\n",
    "    * [`no-plain`] Restrict to non-plain fields\n",
    "    * [`restrict-4`] Restrict to title, text, opening_text and heading\n",
    "    * [`restrict-2`] Restrict to title and text\n",
    "   \n",
    "   These modifications are independent (e.g. there is rescoring in `no-plain` and plain fields are used in `restrict-4`)\n",
    "\n",
    "## Data\n",
    "\n",
    "The data with which the benchmark will be carried out is composed of keywords in course descriptions, for which we know the relevant wikipage from manual tagging.\n",
    "\n",
    "A random subset of keywords will be selected every time to prevent caching at both elasticsearch level and file system level.\n",
    "\n",
    "## Procedure\n",
    "\n",
    "For each setting (i.e. choice of (number_of_shards, query)), we will randomly select *n* keywords from the course descriptions, then run both a wikipedia api request and an elasticsearch request for each of them. We will keep track of the execution time and we will evaluate the quality of the results by checking whether the manually-tagged page associated to the keywords is contained in the list of results.\n",
    "\n",
    "## Disclaimer\n",
    "\n",
    "All requests will be directed to the graph-ai-test server, which runs elasticsearch on a regular HDD. Replacing that with an SDD would improve performance presumably 5 to 10-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "490f0216-1c90-42b6-91d3-4ff31f34c4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec47e33-96b0-493e-bc1b-0729f5d8f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from concept_detection.interfaces.es import ES\n",
    "from concept_detection.interfaces.wp import WP\n",
    "from concept_detection.interfaces.db import DB\n",
    "\n",
    "from concept_detection.test.courses.compare import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e436df-d5ec-49e2-8302-51644a9a0c91",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "We instantiate the interfaces to communicate with the database and the wikipedia api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d04cae3-62b5-4c63-bec5-a3909264e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DB()\n",
    "wp = WP()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0ec603-7653-4e86-a901-1a3ff0848157",
   "metadata": {},
   "source": [
    "We define the grids of values for each variable and the interfaces to communicate with elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee5e65f-cd31-41d8-a710-fc172eaa007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['base', 'no-rescoring', 'no-plain', 'restrict-4', 'restrict-2']\n",
    "\n",
    "es = {1: ES('wikipages-1-shards'), 3: ES('wikipages-3-shards'), 6: ES('wikipages-6-shards'), 12: ES('wikipages')}\n",
    "shards = list(es.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d0540-340b-41a2-b2c0-c4c2250b5079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
